{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ccc7d87",
   "metadata": {},
   "source": [
    "## Given Reg_ID Finding out Top possible Match Likely to be Colluders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import string\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score,classification_report,auc,roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.combine import SMOTETomek\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ec68c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Feature_df = pd.read_pickle('Feature_df.pkl')\n",
    "Feature_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51600c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep]\n",
    "\n",
    "def plot_confusion_mat(y_test, y_pred):\n",
    "    labels = [0, 1]\n",
    "    cm = confusion_matrix(y_test, y_pred, labels)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['0', '1']); ax.yaxis.set_ticklabels(['0', '1']);\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "def get_distance_between_locs(p1_lat, p1_lon, p2_lat, p2_lon):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    lat1 = radians(p1_lat)\n",
    "    lon1 = radians(p1_lon)\n",
    "    lat2 = radians(p2_lat)\n",
    "    lon2 = radians(p2_lon)\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "# Manufacture details handled inphone , separated by \",\" , separated by \" \"\n",
    "def get_MANUFACTURER(device_info):\n",
    "    S =  'Device Name'\n",
    "    T = 'MANUFACTURER'\n",
    "    data = [k for k in device_info.split(':')]\n",
    "    for t in range(len(data)):\n",
    "        if (T in data[t]) or (S in data[t]):\n",
    "            s = re.split(' Device OS| BRAND',data[t+1])[0]\n",
    "            s = s.split(',',1)[0]\n",
    "            if s[0] == ' ' or s[-1]== ' ':\n",
    "                s = s.replace(' ','',1)\n",
    "            return s\n",
    "\n",
    "def get_MODEL(device_info):\n",
    "    S = 'Device Modal'\n",
    "    T = 'MODEL'\n",
    "    data = [k for k in device_info.split(':')]\n",
    "    for t in range(len(data)):\n",
    "        if (T in data[t]) or (S in data[t]):\n",
    "            s = re.split(' Device OS| BRAND',data[t+1])[0]\n",
    "            s = s.split(',',1)[0]\n",
    "            if s[0] == ' ' or s[-1]== ' ':\n",
    "                s = s.replace(' ','',1)\n",
    "            return s\n",
    "def contact_overlap(p1,p2):\n",
    "    p1_ = set(p1) \n",
    "    p2_ = set(p2)\n",
    "    if len(p1_.union(p2_)) == 0:\n",
    "        k = 0\n",
    "    else:\n",
    "        k = ( len(p1_.intersection(p2_))/len(p1_.union(p2_)) ) * 100\n",
    "    return k\n",
    "def app_overlap(p1,p2):\n",
    "    p1_ = set(p1) \n",
    "    p2_ = set(p2)\n",
    "    if len(p1_.union(p2_)) ==0:\n",
    "        k=0\n",
    "    else:\n",
    "        k =( len(p1_.intersection(p2_))/len(p1_.union(p2_)) ) * 100\n",
    "    return k\n",
    "def levenshtein_distance(a,b):\n",
    "    n, m = len(a), len(b)\n",
    "    if n > m:\n",
    "        # Make sure n <= m, to use O(min(n,m)) space\n",
    "        a,b = b,a\n",
    "        n,m = m,n\n",
    "\n",
    "    current = range(n+1)\n",
    "    for i in range(1,m+1):\n",
    "        previous, current = current, [i]+[0]*n\n",
    "        for j in range(1,n+1):\n",
    "            add, delete = previous[j]+1, current[j-1]+1\n",
    "            change = previous[j-1]\n",
    "            if a[j-1] != b[i-1]:\n",
    "                change = change + 1\n",
    "            current[j] = min(add, delete, change)\n",
    "\n",
    "    return current[n]\n",
    "def similarity(A,B):    \n",
    "    if __name__==\"__main__\":\n",
    "        \n",
    "        k = levenshtein_distance(A,B)  #  k is the similarity coeficients between these two strings A,B\n",
    "        if (len(A)+len(B))==0:\n",
    "            k_normalise = float('NaN')\n",
    "        else:\n",
    "            k_normalise = k/(len(A)+len(B))\n",
    "        return k_normalise\n",
    "\n",
    "def get_corresponding_feature(ID_df):\n",
    "    \n",
    "    reg_id   = [ID_df.p1.iloc[0]] \n",
    "    given_id = ID_df.p2.unique().tolist()\n",
    "    All_id   = given_id+reg_id\n",
    "    \n",
    "    import pymssql\n",
    "    cursor = pymssql.connect(server='ec2-15-206-55-153.ap-south-1.compute.amazonaws.com', user='internUser', password='WinZO@123', database='master')\n",
    "    \n",
    "    given_id_str = ','.join(str(u) for u in All_id)\n",
    "\n",
    "    # blocked_users_query = \"\"\"\n",
    "    # SELECT TRID,REGISTRATIONID,BLOCK_REASON ,REASON_TEXT ,CREATED_DATE\n",
    "    # FROM TicTokdb.dbo.STBL_USER_BLOCK\n",
    "    # where REGISTRATIONID in ({})\n",
    "    # \"\"\".format(given_id_str)\n",
    "    # blocked_users_df_temp = pd.read_sql(blocked_users_query, cursor)\n",
    "\n",
    "\n",
    "    user_reg_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,NAME,REGISTRATION_DATE,DEVICE_INFO,STATUS from MongoDB.dbo.stbl_Registration\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_reg_df_temp = pd.read_sql(user_reg_query, cursor)\n",
    "\n",
    "    user_contacts_query = \"\"\"\n",
    "    select TRID,REGISTRATIONID,NAME,CREATED_DATE from MongoDB.DBO.STBL_PHONE_CONTACTS \n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_contacts_df_temp = pd.read_sql(user_contacts_query, cursor)\n",
    "\n",
    "\n",
    "    user_loc_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,LATITUDE,LONGITUDE from TicTokdb.dbo.STBL_USER_LOCATION\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_loc_df_temp = pd.read_sql(user_loc_query, cursor)\n",
    "\n",
    "    user_apps_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,APP_NAME_ID from TicTokdb.dbo.STBL_USER_APP_NAMES\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    #     print(user_apps_query)\n",
    "    user_apps_df_temp = pd.read_sql(user_apps_query, cursor)\n",
    "\n",
    "\n",
    "    user_Rake_query = \"\"\"\n",
    "    SELECT CATEGORY,REGISTRATIONID,RAKE from MongoDB.analysis.DAILY_FORMATWISE_RAKE\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_Rake_df_temp = pd.read_sql(user_Rake_query, cursor)\n",
    "    user_Rake_df_temp = user_Rake_df_temp.loc[user_Rake_df_temp.groupby('REGISTRATIONID').RAKE.idxmax()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    Add_Cash_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,PAYAMOUNT,PAYDATE,PAYSTATUS,CREATED_DATE FROM TicTokdb.dbo.STBL_CASH_IN_WALLET\n",
    "    where REGISTRATIONID in ({}) AND PAYSTATUS = 'SUCCESS'\n",
    "    \"\"\".format(given_id_str)\n",
    "    Add_Cash_df_temp = pd.read_sql(Add_Cash_query, cursor)\n",
    "    Add_Cash_df_temp = Add_Cash_df_temp.loc[Add_Cash_df_temp.groupby('REGISTRATIONID').PAYDATE.idxmin()].reset_index(drop=True)\n",
    "\n",
    "    wb_bazzi_trans_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,CHALLENGE_ID,AMOUNT,TRANS_TYPE FROM TicTokdb.dbo.STBL_WB_BAAZI_TRANSACTION swbt\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_commongames_df_temp = pd.read_sql(wb_bazzi_trans_query, cursor)\n",
    "#################################\n",
    "\n",
    "    user_loc_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    user_apps_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    Add_Cash_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    user_Rake_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    user_commongames_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "#     blocked_users_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    \n",
    "    user_reg_df_temp.set_index(['REGISTRATIONID'],inplace=True)    \n",
    "    user_contacts_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "\n",
    "    credit_df_temp = user_commongames_df_temp[user_commongames_df_temp.TRANS_TYPE == 'C']\n",
    "    debit_df_temp  = user_commongames_df_temp[user_commongames_df_temp.TRANS_TYPE == 'D']\n",
    "\n",
    "#########################################\n",
    "    block_df_temp_list = []\n",
    "    count = 0\n",
    "#     Name_similarity,matching_contact_count = 0,0\n",
    "    user = reg_id[0]\n",
    "    if count%25 == 0:\n",
    "        print(user,count)\n",
    "    count+=1\n",
    "\n",
    "    p1_location = user_loc_df_temp[user_loc_df_temp.index==user]\n",
    "    if p1_location.shape[0] > 0:\n",
    "        p1_lat, p1_lon = p1_location['LATITUDE'].iloc[0], p1_location['LONGITUDE'].iloc[0]\n",
    "    else:\n",
    "        p1_lat, p1_lon = 0, 0\n",
    "    try:\n",
    "        Rake_value_p1 = user_Rake_df_temp[user_Rake_df_temp.index==user]['RAKE'].iloc[0]\n",
    "    except:\n",
    "        Rake_value_p1 = np.nan\n",
    "    try:\n",
    "        Frst_AddCash_p1 = Add_Cash_df_temp[Add_Cash_df_temp.index==user]['PAYAMOUNT'].iloc[0]\n",
    "    except:\n",
    "        Frst_AddCash_p1  = 0\n",
    "# ###        \n",
    "    try:\n",
    "        p1_name   = user_reg_df_temp[user_reg_df_temp.index==user]['NAME'].iloc[0]\n",
    "    except:\n",
    "        p1_name = ''\n",
    "    p1_contact  =  user_contacts_df_temp[user_contacts_df_temp.index==user]['NAME']\n",
    "# ###\n",
    "    p1_app    = user_apps_df_temp[user_apps_df_temp.index==user]['APP_NAME_ID']\n",
    "    p1_game   = set(user_commongames_df_temp[user_commongames_df_temp.index==user]['CHALLENGE_ID'])\n",
    "\n",
    "#############################    \n",
    "    for user2 in given_id:\n",
    "        if (user != user2):\n",
    "\n",
    "            p2_location = user_loc_df_temp[user_loc_df_temp.index==user2]\n",
    "            if p2_location.shape[0] > 0:\n",
    "                p2_lat, p2_lon = p2_location['LATITUDE'].iloc[0], p2_location['LONGITUDE'].iloc[0]\n",
    "            else:\n",
    "                p2_lat, p2_lon = 0, 0 \n",
    "\n",
    "            p1_p2_distance = np.nan\n",
    "            if p1_location.shape[0] > 0 and p2_location.shape[0] > 0:\n",
    "                p1_p2_distance = get_distance_between_locs(p1_lat, p1_lon, p2_lat, p2_lon)   ###\n",
    "###                    \n",
    "            try:\n",
    "                p2_name   = user_reg_df_temp[user_reg_df_temp.index==user2]['NAME'].iloc[0]\n",
    "            except:\n",
    "                p2_name = ''\n",
    "                \n",
    "            Name_similarity = similarity(p1_name,p2_name)\n",
    "            p2_contact  =  user_contacts_df_temp[user_contacts_df_temp.index==user2]['NAME']\n",
    "            matching_contact_count = contact_overlap(p1_contact,p2_contact)\n",
    "###\n",
    "            try:\n",
    "                Rake2 = user_Rake_df_temp[user_Rake_df_temp.index==user2]['RAKE'].iloc[0]\n",
    "            except:\n",
    "                Rake2 = np.nan\n",
    "            try:\n",
    "                Frst_AddCash2 = Add_Cash_df_temp[Add_Cash_df_temp.index==user2]['PAYAMOUNT'].iloc[0]\n",
    "            except:\n",
    "                Frst_AddCash2  = 0\n",
    "            p2_app     = user_apps_df_temp[user_apps_df_temp.index==user2]['APP_NAME_ID']\n",
    "            app_match  = app_overlap(p1_app,p2_app)\n",
    "\n",
    "            p2_game = set(user_commongames_df_temp[user_commongames_df_temp.index==user2]['CHALLENGE_ID'])\n",
    "            common_games = p1_game.intersection(p2_game)\n",
    "\n",
    "            mean_Rake = (Rake_value_p1+Rake2)/2\n",
    "            mean_frst_addcash = (Frst_AddCash_p1+Frst_AddCash2)/2\n",
    "\n",
    "            if len(common_games) != 0 :\n",
    "\n",
    "                common_games_percent_of_A_games = (len(common_games)/len(p1_game) )*100                    \n",
    "                common_games_percent_of_B_games = ( len(common_games)/len(p2_game) )*100\n",
    "                max_common_gameAB__of_A_B   = max(common_games_percent_of_A_games,common_games_percent_of_B_games)\n",
    "\n",
    "                # common_games_A_B_profit   && # common_games_A_B_c_by_d\n",
    "                com_game_credit_A = credit_df_temp[(credit_df_temp.index == user) & (credit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "                com_game_debit_A  = debit_df_temp[(debit_df_temp.index == user) & (debit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "                com_game_credit_B = credit_df_temp[(credit_df_temp.index == user2) & (credit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "                com_game_debit_B  = debit_df_temp[(debit_df_temp.index == user2) & (debit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "\n",
    "                if ((com_game_debit_A+com_game_debit_B) != 0):\n",
    "#                     A_B_Profit = ((com_game_credit_A+com_game_credit_B) - (com_game_debit_A+com_game_debit_B))/(com_game_debit_A+com_game_debit_B)\n",
    "                    A_B_C_BY_D = (com_game_credit_A+com_game_credit_B)/(com_game_debit_A+com_game_debit_B)\n",
    "                else:\n",
    "#                     A_B_Profit =  np.nan\n",
    "                    A_B_C_BY_D =  np.nan\n",
    "\n",
    "                block_df_temp_list.append({\n",
    "                        'P1_regID':user,\n",
    "                        'P2_regID': user2,\n",
    "                        'Name_similarity': Name_similarity,\n",
    "                        'Contacts_Overlap_%':matching_contact_count,\n",
    "                        'p1_p2_distance_KM' : p1_p2_distance,\n",
    "                        'Apps_overlap_%': app_match,\n",
    "                        'A_B_C_BY_D':A_B_C_BY_D,\n",
    "                        'mean_Rake' : mean_Rake,\n",
    "                        'mean_Frst_AddCash_1&2': mean_frst_addcash,\n",
    "                        'max_common_gameAB_%_of_A&B' : max_common_gameAB__of_A_B,\n",
    "#                         'A_B_Profit':A_B_Profit,\n",
    "\n",
    "\n",
    "\n",
    "                    })\n",
    "            else:\n",
    "                block_df_temp_list.append({\n",
    "                    'P1_regID':user,\n",
    "                    'P2_regID': user2,\n",
    "                    'Name_similarity': Name_similarity,\n",
    "                    'Contacts_Overlap_%':matching_contact_count,\n",
    "                    'p1_p2_distance_KM' : p1_p2_distance,\n",
    "                    'Apps_overlap_%': app_match,\n",
    "                    'mean_Rake' : mean_Rake,\n",
    "                    'mean_Frst_AddCash_1&2': mean_frst_addcash\n",
    "                })\n",
    "\n",
    "    #     print('About to Complete')\n",
    "    Test_df = pd.DataFrame(block_df_temp_list)\n",
    "    return Test_df\n",
    "\n",
    "def get_one_week_feature(ID_df):\n",
    "    given_id2 = ID_df.p2.tolist()\n",
    "    given_id1 = ID_df.p1.tolist()\n",
    "    given_id = given_id1 + given_id2\n",
    "    given_id = set(given_id)\n",
    "    given_id = list(given_id)\n",
    "    import pymssql\n",
    "    cursor = pymssql.connect(server='ec2-15-206-55-153.ap-south-1.compute.amazonaws.com', user='internUser', password='WinZO@123', database='master')\n",
    "\n",
    "    given_id_str = ','.join(str(u) for u in given_id)\n",
    "\n",
    "    # blocked_users_query = \"\"\"\n",
    "    # SELECT TRID,REGISTRATIONID,BLOCK_REASON ,REASON_TEXT ,CREATED_DATE\n",
    "    # FROM TicTokdb.dbo.STBL_USER_BLOCK\n",
    "    # where REGISTRATIONID in ({})\n",
    "    # \"\"\".format(given_id_str)\n",
    "    # blocked_users_df_temp = pd.read_sql(blocked_users_query, cursor)\n",
    "\n",
    "\n",
    "    user_reg_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,NAME,REGISTRATION_DATE,DEVICE_INFO,STATUS from MongoDB.dbo.stbl_Registration\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_reg_df_temp = pd.read_sql(user_reg_query, cursor)\n",
    "    \n",
    "    user_contacts_query = \"\"\"\n",
    "    select TRID,REGISTRATIONID,NAME,CREATED_DATE from MongoDB.DBO.STBL_PHONE_CONTACTS \n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_contacts_df_temp = pd.read_sql(user_contacts_query, cursor)\n",
    "\n",
    "\n",
    "    user_loc_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,LATITUDE,LONGITUDE from TicTokdb.dbo.STBL_USER_LOCATION\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_loc_df_temp = pd.read_sql(user_loc_query, cursor)\n",
    "\n",
    "    user_apps_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,APP_NAME_ID from TicTokdb.dbo.STBL_USER_APP_NAMES\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    #     print(user_apps_query)\n",
    "    user_apps_df_temp = pd.read_sql(user_apps_query, cursor)\n",
    "\n",
    "\n",
    "    user_Rake_query = \"\"\"\n",
    "    SELECT CATEGORY,REGISTRATIONID,RAKE from MongoDB.analysis.DAILY_FORMATWISE_RAKE\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_Rake_df_temp = pd.read_sql(user_Rake_query, cursor)\n",
    "    user_Rake_df_temp = user_Rake_df_temp.loc[user_Rake_df_temp.groupby('REGISTRATIONID').RAKE.idxmax()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    Add_Cash_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,PAYAMOUNT,PAYDATE,PAYSTATUS,CREATED_DATE FROM TicTokdb.dbo.STBL_CASH_IN_WALLET\n",
    "    where REGISTRATIONID in ({}) AND PAYSTATUS = 'SUCCESS'\n",
    "    \"\"\".format(given_id_str)\n",
    "    Add_Cash_df_temp = pd.read_sql(Add_Cash_query, cursor)\n",
    "    Add_Cash_df_temp = Add_Cash_df_temp.loc[Add_Cash_df_temp.groupby('REGISTRATIONID').PAYDATE.idxmin()].reset_index(drop=True)\n",
    "\n",
    "    wb_bazzi_trans_query = \"\"\"\n",
    "    SELECT REGISTRATIONID,CHALLENGE_ID,AMOUNT,TRANS_TYPE FROM TicTokdb.dbo.STBL_WB_BAAZI_TRANSACTION swbt\n",
    "    where REGISTRATIONID in ({})\n",
    "    \"\"\".format(given_id_str)\n",
    "    user_commongames_df_temp = pd.read_sql(wb_bazzi_trans_query, cursor)\n",
    "    #################################\n",
    "\n",
    "    user_loc_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    user_apps_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    Add_Cash_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    user_Rake_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    user_commongames_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    user_reg_df_temp.set_index(['REGISTRATIONID'],inplace=True)    \n",
    "    user_contacts_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    \n",
    "    #     blocked_users_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "    \n",
    "\n",
    "    credit_df_temp = user_commongames_df_temp[user_commongames_df_temp.TRANS_TYPE == 'C']\n",
    "    debit_df_temp  = user_commongames_df_temp[user_commongames_df_temp.TRANS_TYPE == 'D']\n",
    "\n",
    "    #########################################\n",
    "#     user_already_processed = set()\n",
    "    block_df_temp_list = []\n",
    "    count = 0\n",
    "    i=0\n",
    "    Name_similarity,matching_contact_count = 0,0\n",
    "    for i in range(len(given_id1)):\n",
    "        user = given_id1[i]\n",
    "        user2 = given_id2[i]\n",
    "        if count%100 == 0:\n",
    "            print(user,count)\n",
    "        count+=1\n",
    "\n",
    "        p1_location = user_loc_df_temp[user_loc_df_temp.index==user]\n",
    "        if p1_location.shape[0] > 0:\n",
    "            p1_lat, p1_lon = p1_location['LATITUDE'].iloc[0], p1_location['LONGITUDE'].iloc[0]\n",
    "        else:\n",
    "            p1_lat, p1_lon = 0, 0\n",
    "        try:\n",
    "            Rake_value_p1 = user_Rake_df_temp[user_Rake_df_temp.index==user]['RAKE'].iloc[0]\n",
    "        except:\n",
    "            Rake_value_p1 = 0\n",
    "        try:\n",
    "            Frst_AddCash_p1 = Add_Cash_df_temp[Add_Cash_df_temp.index==user]['PAYAMOUNT'].iloc[0]\n",
    "        except:\n",
    "            Frst_AddCash_p1  = 0\n",
    "    #        \n",
    "        try:\n",
    "            p1_name   = user_reg_df_temp[user_reg_df_temp.index==user]['NAME'].iloc[0]\n",
    "        except:\n",
    "            p1_name = ''\n",
    "        p1_contact  =  user_contacts_df_temp[user_contacts_df_temp.index==user]['NAME']\n",
    "    \n",
    "        p1_app    = user_apps_df_temp[user_apps_df_temp.index==user]['APP_NAME_ID']\n",
    "        p1_game   = set(user_commongames_df_temp[user_commongames_df_temp.index==user]['CHALLENGE_ID'])\n",
    "\n",
    "    #############################    \n",
    "    # for user2 in given_id2:\n",
    "    # if ((user2 not in user_already_processed)&(user != user2)&(given_id1[i]==user)&(given_id2[i]==user2)):\n",
    "    #     i+=1\n",
    "        p2_location = user_loc_df_temp[user_loc_df_temp.index==user2]\n",
    "        if p2_location.shape[0] > 0:\n",
    "            p2_lat, p2_lon = p2_location['LATITUDE'].iloc[0], p2_location['LONGITUDE'].iloc[0]\n",
    "        else:\n",
    "            p2_lat, p2_lon = 0, 0 \n",
    "\n",
    "        p1_p2_distance = np.nan\n",
    "        if p1_location.shape[0] > 0 and p2_location.shape[0] > 0:\n",
    "            p1_p2_distance = get_distance_between_locs(p1_lat, p1_lon, p2_lat, p2_lon)   ###\n",
    "    ###                    \n",
    "        try:\n",
    "            p2_name   = user_reg_df_temp[user_reg_df_temp.index==user2]['NAME'].iloc[0]\n",
    "        except:\n",
    "            p2_name = ''\n",
    "        Name_similarity = similarity(p1_name,p2_name)\n",
    "        p2_contact  =  user_contacts_df_temp[user_contacts_df_temp.index==user2]['NAME']\n",
    "        matching_contact_count = contact_overlap(p1_contact,p2_contact)\n",
    "    ###\n",
    "        try:\n",
    "            Rake2 = user_Rake_df_temp[user_Rake_df_temp.index==user2]['RAKE'].iloc[0]\n",
    "        except:\n",
    "            Rake2 = 0\n",
    "        try:\n",
    "            Frst_AddCash2 = Add_Cash_df_temp[Add_Cash_df_temp.index==user2]['PAYAMOUNT'].iloc[0]\n",
    "        except:\n",
    "            Frst_AddCash2  = 0\n",
    "        p2_app     = user_apps_df_temp[user_apps_df_temp.index==user2]['APP_NAME_ID']\n",
    "        app_match  = app_overlap(p1_app,p2_app)\n",
    "\n",
    "        p2_game = set(user_commongames_df_temp[user_commongames_df_temp.index==user2]['CHALLENGE_ID'])\n",
    "        common_games = p1_game.intersection(p2_game)\n",
    "\n",
    "        mean_Rake = (Rake_value_p1+Rake2)/2\n",
    "        mean_frst_addcash = (Frst_AddCash_p1+Frst_AddCash2)/2\n",
    "\n",
    "        if len(common_games) != 0 :\n",
    "\n",
    "            common_games_percent_of_A_games = (len(common_games)/len(p1_game) )*100                    \n",
    "            common_games_percent_of_B_games = ( len(common_games)/len(p2_game) )*100\n",
    "            max_common_gameAB__of_A_B   = max(common_games_percent_of_A_games,common_games_percent_of_B_games)\n",
    "\n",
    "        # common_games_A_B_profit   && # common_games_A_B_c_by_d\n",
    "            com_game_credit_A = credit_df_temp[(credit_df_temp.index == user) & (credit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "            com_game_debit_A  = debit_df_temp[(debit_df_temp.index == user) & (debit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "            com_game_credit_B = credit_df_temp[(credit_df_temp.index == user2) & (credit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "            com_game_debit_B  = debit_df_temp[(debit_df_temp.index == user2) & (debit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "\n",
    "            if ((com_game_debit_A+com_game_debit_B) != 0):\n",
    "                A_B_Profit = ((com_game_credit_A+com_game_credit_B) - (com_game_debit_A+com_game_debit_B))/(com_game_debit_A+com_game_debit_B)\n",
    "                A_B_C_BY_D = (com_game_credit_A+com_game_credit_B)/(com_game_debit_A+com_game_debit_B)\n",
    "            else:\n",
    "                A_B_Profit =  np.nan\n",
    "                A_B_C_BY_D =  np.nan\n",
    "\n",
    "            block_df_temp_list.append({\n",
    "                    'P1_regID':user,\n",
    "                    'P2_regID': user2,\n",
    "                    'Name_similarity': Name_similarity,\n",
    "                    'Contacts_Overlap_%':matching_contact_count,\n",
    "                    'p1_p2_distance_KM' : p1_p2_distance,\n",
    "                    'Apps_overlap_%': app_match,\n",
    "                    'A_B_C_BY_D':A_B_C_BY_D,\n",
    "                    'mean_Rake' : mean_Rake,\n",
    "                    'mean_Frst_AddCash_1&2': mean_frst_addcash,\n",
    "                    'max_common_gameAB_%_of_A&B' : max_common_gameAB__of_A_B,\n",
    "    #                         'A_B_Profit':A_B_Profit,\n",
    "\n",
    "\n",
    "\n",
    "                })\n",
    "        else:\n",
    "            block_df_temp_list.append({\n",
    "                'P1_regID':user,\n",
    "                'P2_regID': user2,\n",
    "                'Name_similarity': Name_similarity,\n",
    "                'Contacts_Overlap_%':matching_contact_count,\n",
    "                'p1_p2_distance_KM' : p1_p2_distance,\n",
    "                'Apps_overlap_%': app_match,\n",
    "                'mean_Rake' : mean_Rake,\n",
    "                'mean_Frst_AddCash_1&2': mean_frst_addcash\n",
    "            })\n",
    "\n",
    "#     user_already_processed.add(user)\n",
    "    Test_df = pd.DataFrame(block_df_temp_list)\n",
    "    return Test_df\n",
    "# Test_df.head()\n",
    "\n",
    "def Top_p2(Xtest,classifier_r):\n",
    "    df_ = Xtest.drop(['P1_regID','P2_regID'],axis='columns')\n",
    "    predictions = classifier_r.predict_proba(df_)\n",
    "#     print(predictions)\n",
    "    pd_df = pd.DataFrame(predictions, columns=[\"A\", \"B\"])\n",
    "    pd_df.drop(pd_df[pd_df['B'] < 0.75].index, inplace = True)    #### Not Needed \n",
    "    pd_df.sort_values(\"B\", axis = 0, ascending = False,inplace=True)\n",
    "    \n",
    "    out_df = pd_df.head(5)\n",
    "    out_index = out_df.index\n",
    "    return pd_df,Xtest.iloc[out_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f8f3b",
   "metadata": {},
   "source": [
    "#### Replacing Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766eb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Feature_df.copy()\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df[\"mean_Rake\"] = df[[\"Rake\", \"Rake2\"]].mean(axis=1)\n",
    "df[\"mean_Frst_AddCash_1&2\"] = df[[\"Frst_AddCash\", \"Frst_AddCash2\"]].mean(axis=1)\n",
    "df[\"mean_Frst_AddCash_1&2\"].fillna(value=0, inplace=True)\n",
    "df[\"max_common_gameAB_%_of_A&B\"] = df[[\"common_gameAB_%_of_A\",\"common_gameAB_%_of_B\"]].max(axis=1)\n",
    "df['max_common_gameAB_%_of_A&B'].fillna(value=0, inplace=True)\n",
    "df['A_B_C_BY_D'].fillna(value=0, inplace=True)\n",
    "df['Name_similarity'].fillna(value=df[\"Name_similarity\"].max(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ec061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['P1_regID', 'P2_regID','p1_name','p2_name','Diff_p1block_p2_reg_minutes','Rake','Category','Rake2',\n",
    "       'Category2','common_games','Frst_AddCash', 'Frst_AddCash2','common_gameAB_%_of_A', 'common_gameAB_%_of_B',\n",
    "       'A_B_Profit'],axis='columns',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98768b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210c86e",
   "metadata": {},
   "source": [
    "## Sampling and Splitting the Data\n",
    "#### Random Undersampling and Upsamling using Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "count_class_0, count_class_1 = df.Class.value_counts()\n",
    "# Divide by class\n",
    "df_class_0 = df[df['Class'] == 0]\n",
    "df_class_1 = df[df['Class'] == 1]\n",
    "\n",
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(2000)\n",
    "# df_class_1       = df_class_1.sample(1000,replace=True)\n",
    "df_test_ = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-over-sampling:')\n",
    "print(df_test_.Class.value_counts())\n",
    "\n",
    "y = df_test_.Class\n",
    "X = df_test_.drop(['Class'], axis=1)\n",
    "# print(y.value_counts())\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "print(y_sm.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)\n",
    "# Number of classes in training Data\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165ce4b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_r = RandomForestClassifier(max_depth = 4,n_estimators = 10, criterion = 'entropy', random_state = 15,max_features = \"auto\")\n",
    "classifier_r.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_1 = classifier_r.predict(X_train)\n",
    "print('Training Accuracy :',accuracy_score(y_train,y_pred_1))\n",
    "y_pred  = classifier_r.predict(X_test)\n",
    "print('Testing Accuracy :',accuracy_score(y_test,y_pred))\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "print(\"Classification Report[Randomforest]: \\n\", classification_report(y_test, y_pred))\n",
    "print(\"classifier_r.feature_importances_[Randomforest]: \\n\", classifier_r.feature_importances_)\n",
    "\n",
    "\n",
    "feature_importance_r = classifier_r.feature_importances_\n",
    "col = X_train.columns.values.tolist()\n",
    "feature_df_random = pd.DataFrame(list(zip(col, feature_importance_r)),\n",
    "               columns =['Features', 'Feature_weight'])\n",
    "\n",
    "feature_df_random.sort_values('Feature_weight',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c49a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = list(X_train.columns)\n",
    "cn =['0','1']\n",
    "\n",
    "plt.figure(figsize=(25,5))\n",
    "tree.plot_tree(classifier_r.estimators_[0],feature_names = fn, \n",
    "               class_names=cn,filled=True)\n",
    "\n",
    "print(tree.export_text(classifier_r.estimators_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132e6b9",
   "metadata": {},
   "source": [
    "### In one week possible colluders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import pymssql\n",
    "cursor = pymssql.connect(server='ec2-15-206-55-153.ap-south-1.compute.amazonaws.com', user='internUser', password='WinZO@123', database='master')\n",
    "\n",
    "query= '''\n",
    "select * from (\n",
    "\t\t\t\tSELECT wb1.REGISTRATIONID as p1, wb2.REGISTRATIONID as p2, \n",
    "\t\t\t\tcount(*) as overlap_count\n",
    "\t\t\t\tfrom\n",
    "\t\t\t\t( \n",
    "\t\t\t\tSELECT REGISTRATIONID, CHALLENGE_ID from TicTokdb.dbo.STBL_WB_BAAZI_TRANSACTION swbt \n",
    "\t\t\t\twhere GAME_TYPE = 49 AND CREATED_DATE > '2021-08-01 00:00:00'\n",
    "\t\t\t\t) as wb1\n",
    "\t\t\t\tleft join\n",
    "\t\t\t\t( \n",
    "\t\t\t\tSELECT REGISTRATIONID, CHALLENGE_ID from TicTokdb.dbo.STBL_WB_BAAZI_TRANSACTION swbt \n",
    "                 where GAME_TYPE = 49 AND CREATED_DATE > '2021-08-01 00:00:00'\n",
    "\t\t\t\t) as wb2\n",
    "\t\t\t\ton (wb1.REGISTRATIONID != wb2.REGISTRATIONID) and (wb1.CHALLENGE_ID = wb2.CHALLENGE_ID)\n",
    "\t\t\t\tGROUP BY wb1.REGISTRATIONID, wb2.REGISTRATIONID\n",
    "\t\t\t  ) as wb3\n",
    "where overlap_count> 20;\n",
    "'''#.format(temp_str)\n",
    "ID_df = pd.read_sql(query, cursor)\n",
    "ID_df.dropna(axis=0,inplace=True)\n",
    "ID_df.reset_index(drop=True,inplace=True)\n",
    "print(ID_df.shape)\n",
    "ID_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Test_df = get_one_week_feature(ID_df)\n",
    "\n",
    "Test_df_copy = Test_df.copy()   ## In case need to save Test_df\n",
    "Test_df.dropna(axis=0,inplace=True)  ## Just for Testing You Can check which all rows are Nan and replace them accordingly\n",
    "print(Test_df.shape)\n",
    "\n",
    "prediction_df,Possible_block_ID_df = Top_p2(Test_df,classifier_r)\n",
    "print(prediction_df[prediction_df.B > 0.95].shape)\n",
    "Possible_block_ID_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7926d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125e0c7f",
   "metadata": {},
   "source": [
    "### Get Top_p2 corresponding to given reg_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reg_id = [17772895]\n",
    "temp_str = ','.join(str(u) for u in reg_id)\n",
    "\n",
    "import pandas as pd\n",
    "import pymssql\n",
    "cursor = pymssql.connect(server='ec2-15-206-55-153.ap-south-1.compute.amazonaws.com', user='internUser', password='WinZO@123', database='master')\n",
    "\n",
    "query= '''\n",
    "select * from ( \n",
    "SELECT wb1.REGISTRATIONID as p1, wb2.REGISTRATIONID as p2, \n",
    "count(*) as overlap_count\n",
    "from ( \n",
    "SELECT REGISTRATIONID, CHALLENGE_ID from TicTokdb.dbo.STBL_WB_BAAZI_TRANSACTION swbt\n",
    "where GAME_TYPE = 49 and  REGISTRATIONID in ({})\n",
    ") as wb1\n",
    "left join ( \n",
    "SELECT REGISTRATIONID, CHALLENGE_ID from TicTokdb.dbo.STBL_WB_BAAZI_TRANSACTION swbt\n",
    "where GAME_TYPE = 49\n",
    ") as wb2\n",
    "on (wb1.REGISTRATIONID != wb2.REGISTRATIONID) and (wb1.CHALLENGE_ID = wb2.CHALLENGE_ID)\n",
    "GROUP BY wb1.REGISTRATIONID, wb2.REGISTRATIONID) as wb3\n",
    "where overlap_count>10;\n",
    "'''.format(temp_str)\n",
    "ID_df_1 = pd.read_sql(query, cursor)\n",
    "ID_df_1.dropna(axis=0,inplace=True)   ## Just for Testing You Can check which all rows are Nan and replace them accordingly\n",
    "ID_df_1.reset_index(drop=True,inplace=True)\n",
    "print(ID_df_1.shape)\n",
    "ID_df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0aa903",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Test_df_1 = get_corresponding_feature(ID_df_1)\n",
    "\n",
    "Test_df.dropna(axis=0,inplace=True)  ## Just for Testing You Can check which all rows are Nan and replace them accordingly\n",
    "Test_df_1_copy = Test_df_1.copy()\n",
    "print(Test_df_1.shape)\n",
    "\n",
    "prediction_df_,Top_p2_df = Top_p2(Test_df_1,classifier_r)\n",
    "print(prediction_df_[prediction_df_.B>0.9].shape)\n",
    "Top_p2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f371742",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_id   = [ID_df_1.p1.iloc[0]] \n",
    "given_id = ID_df_1.p2.unique().tolist()\n",
    "All_id   = given_id+reg_id\n",
    "\n",
    "import pymssql\n",
    "cursor = pymssql.connect(server='ec2-15-206-55-153.ap-south-1.compute.amazonaws.com', user='internUser', password='WinZO@123', database='master')\n",
    "\n",
    "given_id_str = ','.join(str(u) for u in All_id)\n",
    "\n",
    "# blocked_users_query = \"\"\"\n",
    "# SELECT TRID,REGISTRATIONID,BLOCK_REASON ,REASON_TEXT ,CREATED_DATE\n",
    "# FROM TicTokdb.dbo.STBL_USER_BLOCK\n",
    "# where REGISTRATIONID in ({})\n",
    "# \"\"\".format(given_id_str)\n",
    "# blocked_users_df_temp = pd.read_sql(blocked_users_query, cursor)\n",
    "\n",
    "\n",
    "user_reg_query = \"\"\"\n",
    "SELECT REGISTRATIONID,NAME,REGISTRATION_DATE,DEVICE_INFO,STATUS from MongoDB.dbo.stbl_Registration\n",
    "where REGISTRATIONID in ({})\n",
    "\"\"\".format(given_id_str)\n",
    "user_reg_df_temp = pd.read_sql(user_reg_query, cursor)\n",
    "user_contacts_query = \"\"\"\n",
    "select TRID,REGISTRATIONID,NAME,CREATED_DATE from MongoDB.DBO.STBL_PHONE_CONTACTS \n",
    "where REGISTRATIONID in ({})\n",
    "\"\"\".format(given_id_str)\n",
    "user_contacts_df_temp = pd.read_sql(user_contacts_query, cursor)\n",
    "\n",
    "\n",
    "user_loc_query = \"\"\"\n",
    "SELECT REGISTRATIONID,LATITUDE,LONGITUDE from TicTokdb.dbo.STBL_USER_LOCATION\n",
    "where REGISTRATIONID in ({})\n",
    "\"\"\".format(given_id_str)\n",
    "user_loc_df_temp = pd.read_sql(user_loc_query, cursor)\n",
    "\n",
    "user_apps_query = \"\"\"\n",
    "SELECT REGISTRATIONID,APP_NAME_ID from TicTokdb.dbo.STBL_USER_APP_NAMES\n",
    "where REGISTRATIONID in ({})\n",
    "\"\"\".format(given_id_str)\n",
    "#     print(user_apps_query)\n",
    "user_apps_df_temp = pd.read_sql(user_apps_query, cursor)\n",
    "\n",
    "\n",
    "user_Rake_query = \"\"\"\n",
    "SELECT CATEGORY,REGISTRATIONID,RAKE from MongoDB.analysis.DAILY_FORMATWISE_RAKE\n",
    "where REGISTRATIONID in ({})\n",
    "\"\"\".format(given_id_str)\n",
    "user_Rake_df_temp = pd.read_sql(user_Rake_query, cursor)\n",
    "user_Rake_df_temp = user_Rake_df_temp.loc[user_Rake_df_temp.groupby('REGISTRATIONID').RAKE.idxmax()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "Add_Cash_query = \"\"\"\n",
    "SELECT REGISTRATIONID,PAYAMOUNT,PAYDATE,PAYSTATUS,CREATED_DATE FROM TicTokdb.dbo.STBL_CASH_IN_WALLET\n",
    "where REGISTRATIONID in ({}) AND PAYSTATUS = 'SUCCESS'\n",
    "\"\"\".format(given_id_str)\n",
    "Add_Cash_df_temp = pd.read_sql(Add_Cash_query, cursor)\n",
    "Add_Cash_df_temp = Add_Cash_df_temp.loc[Add_Cash_df_temp.groupby('REGISTRATIONID').PAYDATE.idxmin()].reset_index(drop=True)\n",
    "\n",
    "wb_bazzi_trans_query = \"\"\"\n",
    "SELECT REGISTRATIONID,CHALLENGE_ID,AMOUNT,TRANS_TYPE FROM TicTokdb.dbo.STBL_WB_BAAZI_TRANSACTION swbt\n",
    "where REGISTRATIONID in ({})\n",
    "\"\"\".format(given_id_str)\n",
    "user_commongames_df_temp = pd.read_sql(wb_bazzi_trans_query, cursor)\n",
    "#################################\n",
    "\n",
    "user_loc_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "user_apps_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "Add_Cash_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "user_Rake_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "user_commongames_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "#     blocked_users_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "\n",
    "user_reg_df_temp.set_index(['REGISTRATIONID'],inplace=True)    \n",
    "user_contacts_df_temp.set_index(['REGISTRATIONID'],inplace=True)\n",
    "\n",
    "credit_df_temp = user_commongames_df_temp[user_commongames_df_temp.TRANS_TYPE == 'C']\n",
    "debit_df_temp  = user_commongames_df_temp[user_commongames_df_temp.TRANS_TYPE == 'D']\n",
    "\n",
    "#########################################\n",
    "block_df_temp_list = []\n",
    "count = 0\n",
    "#     Name_similarity,matching_contact_count = 0,0\n",
    "user = reg_id[0]\n",
    "if count%25 == 0:\n",
    "    print(user,count)\n",
    "count+=1\n",
    "\n",
    "p1_location = user_loc_df_temp[user_loc_df_temp.index==user]\n",
    "if p1_location.shape[0] > 0:\n",
    "    p1_lat, p1_lon = p1_location['LATITUDE'].iloc[0], p1_location['LONGITUDE'].iloc[0]\n",
    "else:\n",
    "    p1_lat, p1_lon = 0, 0\n",
    "try:\n",
    "    Rake_value_p1 = user_Rake_df_temp[user_Rake_df_temp.index==user]['RAKE'].iloc[0]\n",
    "except:\n",
    "    Rake_value_p1 = np.nan\n",
    "try:\n",
    "    Frst_AddCash_p1 = Add_Cash_df_temp[Add_Cash_df_temp.index==user]['PAYAMOUNT'].iloc[0]\n",
    "except:\n",
    "    Frst_AddCash_p1  = 0\n",
    "# ###        \n",
    "try:\n",
    "    p1_name   = user_reg_df_temp[user_reg_df_temp.index==user]['NAME'].iloc[0]\n",
    "except:\n",
    "    p1_name = ''\n",
    "        \n",
    "p1_contact  =  user_contacts_df_temp[user_contacts_df_temp.index==user]['NAME']\n",
    "# ###\n",
    "p1_app    = user_apps_df_temp[user_apps_df_temp.index==user]['APP_NAME_ID']\n",
    "p1_game   = set(user_commongames_df_temp[user_commongames_df_temp.index==user]['CHALLENGE_ID'])\n",
    "\n",
    "#############################    \n",
    "for user2 in given_id:\n",
    "    if (user != user2):\n",
    "\n",
    "        p2_location = user_loc_df_temp[user_loc_df_temp.index==user2]\n",
    "        if p2_location.shape[0] > 0:\n",
    "            p2_lat, p2_lon = p2_location['LATITUDE'].iloc[0], p2_location['LONGITUDE'].iloc[0]\n",
    "        else:\n",
    "            p2_lat, p2_lon = 0, 0 \n",
    "\n",
    "        p1_p2_distance = np.nan\n",
    "        if p1_location.shape[0] > 0 and p2_location.shape[0] > 0:\n",
    "            p1_p2_distance = get_distance_between_locs(p1_lat, p1_lon, p2_lat, p2_lon)   ###\n",
    "###                    \n",
    "        try:\n",
    "            p2_name   = user_reg_df_temp[user_reg_df_temp.index==user2]['NAME'].iloc[0]\n",
    "        except:\n",
    "            p2_name = ''\n",
    "\n",
    "        Name_similarity = similarity(p1_name,p2_name)\n",
    "        p2_contact  =  user_contacts_df_temp[user_contacts_df_temp.index==user2]['NAME']\n",
    "        matching_contact_count = contact_overlap(p1_contact,p2_contact)\n",
    "###\n",
    "        try:\n",
    "            Rake2 = user_Rake_df_temp[user_Rake_df_temp.index==user2]['RAKE'].iloc[0]\n",
    "        except:\n",
    "            Rake2 = np.nan\n",
    "        try:\n",
    "            Frst_AddCash2 = Add_Cash_df_temp[Add_Cash_df_temp.index==user2]['PAYAMOUNT'].iloc[0]\n",
    "        except:\n",
    "            Frst_AddCash2  = 0\n",
    "        p2_app     = user_apps_df_temp[user_apps_df_temp.index==user2]['APP_NAME_ID']\n",
    "        app_match  = app_overlap(p1_app,p2_app)\n",
    "\n",
    "        p2_game = set(user_commongames_df_temp[user_commongames_df_temp.index==user2]['CHALLENGE_ID'])\n",
    "        common_games = p1_game.intersection(p2_game)\n",
    "\n",
    "        mean_Rake = (Rake_value_p1+Rake2)/2\n",
    "        mean_frst_addcash = (Frst_AddCash_p1+Frst_AddCash2)/2\n",
    "\n",
    "        if len(common_games) != 0 :\n",
    "\n",
    "            common_games_percent_of_A_games = (len(common_games)/len(p1_game) )*100                    \n",
    "            common_games_percent_of_B_games = ( len(common_games)/len(p2_game) )*100\n",
    "            max_common_gameAB__of_A_B   = max(common_games_percent_of_A_games,common_games_percent_of_B_games)\n",
    "\n",
    "            # common_games_A_B_profit   && # common_games_A_B_c_by_d\n",
    "            com_game_credit_A = credit_df_temp[(credit_df_temp.index == user) & (credit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "            com_game_debit_A  = debit_df_temp[(debit_df_temp.index == user) & (debit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "            com_game_credit_B = credit_df_temp[(credit_df_temp.index == user2) & (credit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "            com_game_debit_B  = debit_df_temp[(debit_df_temp.index == user2) & (debit_df_temp.CHALLENGE_ID.isin(common_games))]['AMOUNT'].sum()\n",
    "\n",
    "            if ((com_game_debit_A+com_game_debit_B) != 0):\n",
    "#                     A_B_Profit = ((com_game_credit_A+com_game_credit_B) - (com_game_debit_A+com_game_debit_B))/(com_game_debit_A+com_game_debit_B)\n",
    "                A_B_C_BY_D = (com_game_credit_A+com_game_credit_B)/(com_game_debit_A+com_game_debit_B)\n",
    "            else:\n",
    "#                     A_B_Profit =  np.nan\n",
    "                A_B_C_BY_D =  np.nan\n",
    "\n",
    "            block_df_temp_list.append({\n",
    "                    'P1_regID':user,\n",
    "                    'P2_regID': user2,\n",
    "                    'Name_similarity': Name_similarity,\n",
    "                    'Contacts_Overlap_%':matching_contact_count,\n",
    "                    'p1_p2_distance_KM' : p1_p2_distance,\n",
    "                    'Apps_overlap_%': app_match,\n",
    "                    'A_B_C_BY_D':A_B_C_BY_D,\n",
    "                    'mean_Rake' : mean_Rake,\n",
    "                    'mean_Frst_AddCash_1&2': mean_frst_addcash,\n",
    "                    'max_common_gameAB_%_of_A&B' : max_common_gameAB__of_A_B,\n",
    "#                         'A_B_Profit':A_B_Profit,\n",
    "\n",
    "\n",
    "\n",
    "                })\n",
    "        else:\n",
    "            block_df_temp_list.append({\n",
    "                'P1_regID':user,\n",
    "                'P2_regID': user2,\n",
    "                'Name_similarity': Name_similarity,\n",
    "                'Contacts_Overlap_%':matching_contact_count,\n",
    "                'p1_p2_distance_KM' : p1_p2_distance,\n",
    "                'Apps_overlap_%': app_match,\n",
    "                'mean_Rake' : mean_Rake,\n",
    "                'mean_Frst_AddCash_1&2': mean_frst_addcash\n",
    "            })\n",
    "\n",
    "#     print('About to Complete')\n",
    "Test_df = pd.DataFrame(block_df_temp_list)\n",
    "# return Test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df5e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
